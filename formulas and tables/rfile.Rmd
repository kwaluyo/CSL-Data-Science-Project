---
title: Data Science Project Pt. 2 (MAST90107)
subtitle: Final Report, Semester 2 
author:
  - Kartika Waluyo, 1000555
  - Vrinda Rajendar Rajanahally, 1129446
output: 
  pdf_document:
    fig_caption: TRUE
    
---
\centering
\raggedright
\newpage
\tableofcontents

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

![Sample from Various Tissues (GTEx Portal, 2021)](../figs/fig1.png)


![Data Splitting for Training, validation, and Test Set (3.1. Cross-Validation: Evaluating Estimator Performance, 2021)](../figs/fig2.png)


![Rough Illustration on How XGBoost Works (How XGBoost Works - Amazon SageMaker, 2021)](../figs/fig3.png)

![Biological Neural Network (Welcome to SEER Training | SEER Training, 2021)](../figs/fig4.png)

![Perceptron (Sand et al., 2019)](../figs/fig5.png)

![Multi-layer Neural Network (An Overview on Multilayer Perceptron (MLP), 2021)](../figs/fig6.png)

![Neural Network Algorithm](../figs/fig7.png)

![Illustration of Our Neural Network](../figs/fig8.png)

![XGBoost Gridsearch Results](../figs/fig9.png)

![Neural network Gridsearch Results](../figs/fig10.png)

![Test Prediction Correlation with Median Line](../figs/fig11.png)













$F_n = F_{n-1} + \eta\Delta_n$     (1)


$F_m(X) = F_{m-1}(X) + a_mh_m(X,r_{m-1})$     (2)


$$
ENSpred = \frac{1}{2}NNpred + \frac{1}{2}XGBpred =
\frac{1}{2}\begin{bmatrix}
\hat{y}_{11} & \cdots & \hat{y}_{1p}\\
\vdots & \ddots\\
\hat{y}_{n1} & \cdots & \hat{y}_{np}\\
\end{bmatrix} + 
\frac{1}{2}\begin{bmatrix}
\hat{z}_{11} & \cdots & \hat{z}_{1p}\\
\vdots & \ddots\\
\hat{z}_{n1} & \cdots & \hat{z}_{np}\\
\end{bmatrix} (3)
$$



```{r echo=FALSE}
library(knitr)

xgb_result = data.frame(MAE=c(0.1775177,0.6653771), MSE=c(0.05393484, 0.735219))
rownames(xgb_result) = c("Training", "Test")

nn_result = data.frame(MAE=c(0.5993975,0.6464047), MSE=c(0.6128888, 0.6931747))
rownames(nn_result) = c("Training", "Test")

coef_result = data.frame(Training=c(0.990975,0.6278658,0.9205496), Test=c(0.4364947, 0.4887672,0.4976427))
rownames(coef_result) = c("XGBoost", "Neural Network", "Ensemble")
```


```{r echo=FALSE, results='asis'}
kable(xgb_result, "latex", align='c', caption='XGBoost Final Model Result')
```


```{r echo=FALSE, results='asis'}
kable(nn_result, "latex", align='c', caption='Neural Network Final Model Result')
```


```{r echo=FALSE, results='asis'}
kable(coef_result, "latex", align='c', caption='Median Correlation')
```













